{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac4ca930580ea82",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data 3550 Final Project\n",
    "### Ayman Boules, Katherine Simon, Nicholas Sartino, Sammi Hamdan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e6373303a0bbb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127c8924e6fad4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T04:37:44.134630Z",
     "start_time": "2023-11-17T04:37:44.131592Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Installs (comment out if you don't need)\n",
    "\n",
    "# !pip-install missingno\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ba825ea3a47b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T04:39:36.973631Z",
     "start_time": "2023-11-17T04:39:34.635837Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
    "\n",
    "from numpy import arange\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.max_columns',200) #allows for up to 200 columns to be displayed when viewing a dataframe\n",
    "pd.set_option('display.max_rows',100)\n",
    "# The following was commented out as it is deprecated and no longer works with current version.\n",
    "#plt.style.use('seaborn') # a style that can be used for plots - see style reference above\n",
    "\n",
    "# trick to widen the screen\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "#Widens the code landscape \n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc5c2be3272d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T04:39:37.015582Z",
     "start_time": "2023-11-17T04:39:36.972962Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('College_Admission_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940c0b3f7e093b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T04:39:40.872753Z",
     "start_time": "2023-11-17T04:39:40.866603Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ee5660b5e6fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T04:40:05.296703Z",
     "start_time": "2023-11-17T04:40:05.098515Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb9cacb9698162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T04:40:09.898488Z",
     "start_time": "2023-11-17T04:40:09.854858Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x='Carnegie Classification 2010: Basic',y='Enrolled total', data=df)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x='Carnegie Classification 2010: Basic', y='Applicants total', data=df)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the target variable and features\n",
    "X = df.drop('Carnegie Classification 2010: Basic', axis=1)\n",
    "y = df['Carnegie Classification 2010: Basic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical target variable into a numerical variable.\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Convert the encoded labels back to the original categories\n",
    "# y = le.inverse_transform(y_encoded)\n",
    "\n",
    "# Convert categorical features into numerical features.\n",
    "df_dummies = pd.get_dummies(X, drop_first=True)\n",
    "df_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with missing values and their counts\n",
    "missing_counts = df_dummies.isnull().sum()\n",
    "\n",
    "# Filter and print columns with missing values\n",
    "columns_with_missing_values = missing_counts[missing_counts > 0]\n",
    "print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imputation\n",
    "* There are a lot of variables with missing values. Many of them are correlated as well. For example, all of the enrollment variables have exactly 2 missing values.\n",
    "* The goal in this section will be to try to maintain the representation of the data, which means that no statistical value will be used to fill in an NA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules that will be followed:\n",
    "* columns having at least half of its values being missing values will be dropped.\n",
    "* columns having a significant number of missing values (>=100) will have its values substituted with the median (assuming a normal distribution).\n",
    "* columns columns having an insignificant number of missing values will be substituted with appropriate values that indicate that those values were not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns with a very large amount of missing values\n",
    "\n",
    "# Threshold\n",
    "prop = 0.5\n",
    "\n",
    "# Drop columns with more than 'prop' proportion of missing values\n",
    "df_filtered = df_dummies.dropna(thresh=int(df_dummies.shape[0] * prop), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling columns having a significant number of missing values\n",
    "\n",
    "# Threshold\n",
    "min_missing_values = 100\n",
    "\n",
    "# Go through each column in the DataFrame\n",
    "for col in df_filtered.columns:\n",
    "    # If the column has 100 or more missing values\n",
    "    if df_filtered[col].isna().sum() >= min_missing_values:\n",
    "        # Fill the missing values with the median of the column\n",
    "        df_filtered[col].fillna(df_filtered[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling columns having an insignificant number of missing values.\n",
    "\n",
    "# Fill in the rest of the missing values with -1.\n",
    "df_filtered.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with missing values and their counts\n",
    "missing_counts = df_filtered.isnull().sum()\n",
    "\n",
    "# Filter and print columns with missing values\n",
    "columns_with_missing_values = missing_counts[missing_counts > 0]\n",
    "print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y_encoded,test_size=0.3,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Section\n",
    "* Categorical variables were converted into numerical variables.\n",
    "* Missing values were handled according to the rules determined.\n",
    "* The data was split into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a67a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "582f6568",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46ee3b63",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Drop 'Name' column from X_train and X_test\n",
    "X_train = X_train.drop('Name', axis=1)\n",
    "X_test = X_test.drop('Name', axis=1)\n",
    "\n",
    "print(X_train.dtypes)\n",
    "print(X_test.dtypes)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# If categorical columns are present, encode them using pd.get_dummies()\n",
    "if categorical_columns:\n",
    "    X_train_encoded = pd.get_dummies(X_train, columns=categorical_columns, drop_first=True)\n",
    "    X_test_encoded = pd.get_dummies(X_test, columns=categorical_columns, drop_first=True)\n",
    "    \n",
    "    # Display information about the encoded data\n",
    "    X_train_encoded.info()\n",
    "    X_test_encoded.info()\n",
    "\n",
    "    # Ensure both X_train_encoded and X_test_encoded have the same columns\n",
    "    common_columns = list(set(X_train_encoded.columns) & set(X_test_encoded.columns))\n",
    "    X_train_final = X_train_encoded[common_columns]\n",
    "    X_test_final = X_test_encoded[common_columns]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e37078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train_final, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_final)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Get a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained Decision Tree Classifier\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to associate feature names with their importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train_final.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top N most important features\n",
    "top_n = 10  # Set the number of top features you want to display\n",
    "top_features = feature_importance_df.head(top_n)\n",
    "print(top_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d9750a",
   "metadata": {},
   "source": [
    "Based on the code above, the top ten features deamed important by the Decision Tree Classifier are outputted. It shows that among all the features, the \"Estimated graduate enrollment, total\" is the most significant feature with a importance value of 0.127.  \n",
    "\n",
    "Estimated graduate enrollment, total: This feature might have high importance because it could be strongly correlated or indicative of certain types of institutions that fall into specific Carnegie classifications. Institutions with higher graduate enrollment might exhibit characteristics associated with certain categories within the classification.  \n",
    "\n",
    "SAT Critical Reading 25th percentile score: This could indicate the academic profile of students, which might align with the criteria used in the Carnegie classification system to differentiate between different types of institutions.  \n",
    "\n",
    "Endowment assets per FTE enrollment: Institutions full-time equivalent (FTE) enrollment might belong to a specific category within the Carnegie classification due to financial resources or institutional characteristics associated with these levels of funding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "\n",
    "# Fit the Decision Tree Classifier with max_depth=5\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "clf.fit(X_train_final, y_train)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(clf, filled=True, feature_names=X_train_final.columns.tolist(), class_names=[str(c) for c in le.classes_])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a range of depths to search through\n",
    "param_grid = {'max_depth': range(1, 20)}  # Adjust the range as needed\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train_final, y_train)\n",
    "\n",
    "# Get the best estimator and its parameters\n",
    "dt_best = grid_search.best_estimator_\n",
    "best_depth = dt_best.get_params()['max_depth']\n",
    "print(f\"Best tree depth: {best_depth}\")\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "dt_best.fit(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the final decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(dt_best, filled=True, feature_names=X_train_final.columns.tolist(), class_names=[str(c) for c in le.classes_])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff111e",
   "metadata": {},
   "source": [
    "There seems to be no difference in the dt_best model and the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19cb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
